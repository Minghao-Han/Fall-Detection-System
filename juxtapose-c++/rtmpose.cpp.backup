#include "rtmpose.hpp"
#include "utils.hpp"
#include "hbDNNheader.h"
#include <filesystem>

RTMPose::RTMPose(const string& model_path, const string& device) {
    if (!filesystem::exists(model_path)) {
        throw std::runtime_error("Model path does not exist.");
    }
    // 第一步加载模型
    hbPackedDNNHandle_t packed_dnn_handle;
    const char* model_file_name= "./mobilenetv1.bin";
    hbDNNInitializeFromFiles(&packed_dnn_handle, &model_file_name, 1);

    // 第二步获取模型名称
    const char **model_name_list;
    int model_count = 0;
    hbDNNGetModelNameList(&model_name_list, &model_count, packed_dnn_handle);

    // 第三步获取dnn_handle
    hbDNNGetModelHandle(&(this->dnn_handle), packed_dnn_handle, model_name_list[0]);

    // 第四步准备输入数据
    hbDNNGetInputTensorProperties(&(input_properties), dnn_handle, 0);
    // 第五步准备模型输出数据的空间
    hbDNNGetOutputCount(&model_output_count, dnn_handle);

    

    // const char* providers[] = {device == "cuda" ? "CUDAExecutionProvider" : "CPUExecutionProvider"};

    model_input_size = Size(192, 256);
    mean = Scalar(123.675, 116.28, 103.53);
    std = Scalar(58.395, 57.12, 57.375);
    // this->device = device;

    cout << "Loaded " << model_path << " onnx model in."  << endl;
}

tuple<vector<vector<Point2f>>, vector<vector<float>>> RTMPose::operator()(
    const Mat& im,
    const vector<Rect2f>& bboxes
) {
    vector<vector<Point2f>> keypoints;
    vector<vector<float>> scores;
    vector<Rect2f> bboxes_local = bboxes.empty() ? vector<Rect2f>{Rect(0, 0, im.cols, im.rows)} : bboxes;

    for (const auto& bbox : bboxes_local) {
        Mat img;
        Point2f center, scale;
        tie(img, center, scale) = preprocess(im, bbox);
        vector<Mat> outputs = inference(img);
        vector<vector<Point2f>> kpts;
        vector<vector<float>> score;
        tie(kpts, score) = postprocess(outputs, center, scale);

        keypoints.insert(keypoints.end(), kpts.begin(), kpts.end());
        scores.insert(scores.end(), score.begin(), score.end());
    }

    return make_tuple(keypoints, scores);
}

vector<Mat> RTMPose::inference(const Mat& im) {
    Mat im_transposed;
    im.convertTo(im_transposed, CV_32F);
    im_transposed = im_transposed.t();

    // 第四步准备输入数据
    hbDNNTensor input_tensor;
    vector<int64_t> input_shape = {1, im_transposed.channels(), im_transposed.rows, im_transposed.cols};
    input_tensor.properties = input_properties;
    auto &mem = input_tensor.sysMem[0];
    int yuv_length = 224 * 224 * 3;
    hbSysAllocCachedMem(&mem, yuv_length);
    input_tensor.properties.alignedShape = input_tensor.properties.validShape;
    //memcpy(mem.virAddr, yuv_data, yuv_length);
    //hbSysFlushMem(&mem, HB_SYS_MEM_CACHE_CLEAN);


    // 准备输出
    hbDNNTensor *output_tensors = new hbDNNTensor[model_output_count];
    for (int i = 0; i < model_output_count; i++) {
        hbDNNTensorProperties &output_properties = output_tensors[i].properties;
        hbDNNGetOutputTensorProperties(&output_properties, dnn_handle, i);

        // // 获取模型输出尺寸
        // int out_aligned_size = 4;
        // for (int j = 0; j < output_properties.alignedShape.numDimensions; j++) {
        //     out_aligned_size =
        //         out_aligned_size * output_properties.alignedShape.dimensionSize[j];
        // }

        hbSysMem &mem = output_tensors[i].sysMem[0];
        hbSysAllocCachedMem(&mem, output_properties.alignedByteSize);
    }

    // 第六步推理模型
    hbDNNTaskHandle_t task_handle = nullptr;
    hbDNNInferCtrlParam infer_ctrl_param;
    HB_DNN_INITIALIZE_INFER_CTRL_PARAM(&infer_ctrl_param);
    hbDNNInfer(&task_handle,&output_tensors,&input_tensor,dnn_handle,&infer_ctrl_param);

    // 第七步等待任务结束
    hbDNNWaitTaskDone(task_handle, 0);
    hbDNNReleaseTask(task_handle);

    // output_tensors bpu->cpu
    hbSysFlushMem(&(output_tensors->sysMem[0]), HB_SYS_MEM_CACHE_INVALIDATE);

    // 释放内存
    hbSysFreeMem(&(input_tensor.sysMem[0]));
    hbSysFreeMem(&(output_tensors->sysMem[0]));

    Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU);
    Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
        memory_info, im_transposed.ptr<float>(), im_transposed.total(), input_shape.data(), input_shape.size()
    );

    vector<const char*> output_node_names = {session.GetOutputName(0, Ort::AllocatorWithDefaultOptions()),
                                             session.GetOutputName(1, Ort::AllocatorWithDefaultOptions())};

    vector<Ort::Value> output_tensors = session.Run(Ort::RunOptions{nullptr}, &input_tensor, output_node_names.data(), output_node_names.size());

    vector<Mat> outputs;
    for (auto& output_tensor : output_tensors) {
        Mat output_mat(output_tensor.GetTensorTypeAndShapeInfo().GetShape(), CV_32F, output_tensor.GetTensorMutableData<float>());
        outputs.push_back(output_mat);
    }

    return outputs;
}

tuple<Mat, Point2f, Point2f> RTMPose::preprocess(const Mat& img, const Rect2f& bbox) {
    Point2f center, scale;
    tie(center, scale) = bbox_xyxy2cs(bbox, 1.25);

    Mat resized_img;
    tie(resized_img, scale) = top_down_affine(model_input_size, scale, center, img);

    if (mean != Scalar()) {
        resized_img.convertTo(resized_img, CV_32F);

        Mat mean_mat(resized_img.size(), resized_img.type(), mean);
        Mat std_mat(resized_img.size(), resized_img.type(), std);

        resized_img = (resized_img - mean_mat) / std_mat;
    }

    return make_tuple(resized_img, center, scale);
}

tuple<vector<vector<Point2f>>, vector<vector<float>>> RTMPose::postprocess(
    const vector<Mat>& outputs,
    const Point2f& center,
    const Point2f& scale,
    float simcc_split_ratio
) {
    vector<vector<Point2f>> locs;
    vector<vector<float>> scores;
    tie(locs, scores) = get_simcc_maximum(outputs[0], outputs[1]);

    for (auto& keypoints : locs) {
        for (auto& point : keypoints) {
            point /= simcc_split_ratio;
            point = point / model_input_size * scale;
            point += center - scale / 2;
        }
    }

    return make_tuple(locs, scores);
}
